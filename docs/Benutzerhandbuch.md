# Benutzerhandbuch: FSCM Multi-Agent System

## Ãœbersicht

Das FSCM Multi-Agent System ermÃ¶glicht es, Markdown-Dateien mit Fragen automatisch durch KI-Agenten beantworten zu lassen. Die Antworten werden direkt in die Datei eingefÃ¼gt. Das System unterstÃ¼tzt mehrere spezialisierte Agenten, eine globale Wissensdatenbank und automatisches Rate-Limit-Handling.

## Schnellstart

```bash
# Fragen beantworten und Datei aktualisieren
python main.py Agents process-file meine_fragen.md

# Vorschau ohne Ã„nderungen (Dry-Run)
python main.py Agents process-file meine_fragen.md --dry-run

# Mit Projekt-Filter (RAG-Abfragen nur aus Projekt 99)
python main.py Agents process-file meine_fragen.md -p 99

# Mit Debug-Ausgabe (zeigt System Prompts, Messages, Tool Calls)
python main.py Agents process-file meine_fragen.md -d
```

---

## Setup-Prozess

Bevor Sie das System nutzen kÃ¶nnen, mÃ¼ssen folgende Schritte durchgefÃ¼hrt werden:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Setup-Reihenfolge                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. .env             â†’ API-Keys konfigurieren                   â”‚
â”‚  2. agents.yaml      â†’ Agenten & LLMs konfigurieren             â”‚
â”‚  3. Knowledge RAG    â†’ Globales D365-Wissen importieren         â”‚
â”‚  4. Project RAG      â†’ Projektspezifische Dokumente importieren â”‚
â”‚  5. Fragenkatalog    â†’ Markdown-Datei mit Fragen erstellen      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Schritt 1: Environment-Konfiguration (.env)

Erstellen Sie eine `.env` Datei im Projektverzeichnis:

```bash
cp .env.example .env
```

**Erforderliche API-Keys:**

| Variable | Beschreibung | Erforderlich fÃ¼r |
|----------|--------------|------------------|
| `ANTHROPIC_API_KEY` | Anthropic Claude API | `llm_provider: claude` |
| `OPENAI_API_KEY` | OpenAI API | `llm_provider: openai` |
| `TAVILY_API_KEY` | Tavily Web-Suche | `web_search` Tool |

**Beispiel `.env`:**

```bash
# LLM Provider (mindestens einer erforderlich)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx
OPENAI_API_KEY=sk-proj-xxxxx

# Ollama (fÃ¼r lokale LLMs)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Web-Suche
TAVILY_API_KEY=tvly-xxxxx

# Agent-Einstellungen
AGENT_MAX_ITERATIONS=10
AGENT_VERBOSE=true
```

**API-Keys erhalten:**
- Anthropic: https://console.anthropic.com/
- OpenAI: https://platform.openai.com/api-keys
- Tavily: https://tavily.com/

---

### Schritt 2: Agent-Konfiguration (config/agents.yaml)

Konfigurieren Sie die Agenten nach Ihren BedÃ¼rfnissen:

```yaml
agents:
  research:
    name: "Research Agent"
    role: "researcher"
    role_file: "de/research.md"      # Minimale Rolle (deutsch)
    # role_file: "research.md"       # AusfÃ¼hrliche Rolle
    # role_file: "en/research.md"    # Minimale Rolle (englisch)
    llm_provider: "ollama"           # ollama, claude, openai
    model: "llama3"                  # Modellname
    temperature: 0.3
    tools:
      - "web_search"
      - "query_knowledge_base"
      - "list_projects"
      - "save_markdown"
```

**Wichtige Entscheidungen:**

| Einstellung | Optionen | Empfehlung |
|-------------|----------|------------|
| `llm_provider` | ollama, claude, openai | `ollama` fÃ¼r Kosten, `openai` fÃ¼r QualitÃ¤t |
| `role_file` | de/*.md, en/*.md, *.md | `de/` fÃ¼r kurze Prompts, Root fÃ¼r ausfÃ¼hrliche |
| `temperature` | 0.0 - 1.0 | 0.3 fÃ¼r prÃ¤zise, 0.7 fÃ¼r kreative Antworten |

---

### Schritt 3: Globale Wissensdatenbank (Knowledge RAG)

Importieren Sie allgemeines D365-Wissen, das fÃ¼r **alle** Projekte verfÃ¼gbar sein soll:

```bash
# Ordner mit D365-Dokumentation importieren
python main.py RAG add-knowledge -f ./d365_dokumentation

# Einzelne Datei importieren
python main.py RAG add-knowledge -f ./D365_Finance_Guide.pdf

# Inhalt prÃ¼fen
python main.py RAG list-knowledge
```

**Geeignete Dokumente:**
- Microsoft D365 Dokumentation (PDFs)
- Best Practices & Lessons Learned
- Architektur-LeitfÃ¤den
- Technische Referenzen

**Ausgabe:**
```
ğŸ“š Adding to global knowledge base...
  âœ… D365_Finance_Guide.pdf (234 chunks)
  âœ… Integration_Best_Practices.md (56 chunks)
  âœ… Data_Migration_Handbook.pdf (189 chunks)
```

---

### Schritt 4: Projekt-Wissensdatenbank (Project RAG)

Importieren Sie projektspezifische Dokumente mit einer `project_id`:

```bash
# Projekt-Dokumente importieren (Projekt-ID: 99)
python main.py RAG addfiles -f ./projekt_99_docs -p 99

# Weiteres Projekt
python main.py RAG addfiles -f ./projekt_100_docs -p 100

# Projekt-Dokumente anzeigen
python main.py RAG delete --project 99 --dry-run
```

**Geeignete Dokumente:**
- Anforderungsdokumente
- Lastenheft / Pflichtenheft
- ProjektplÃ¤ne
- Architektur-Diagramme
- Meeting-Protokolle

**Ausgabe:**
```
ğŸ“ Adding to project 99...
  âœ… Anforderungen.pdf (123 chunks)
  âœ… Lastenheft_v2.docx (89 chunks)
  âœ… Architektur_Entwurf.md (45 chunks)
```

---

### Schritt 5: Fragenkatalog erstellen

Erstellen Sie eine Markdown-Datei mit Ihren Fragen:

```markdown
# Projektname: D365 Finance EinfÃ¼hrung

## Kontext

### Unternehmen
- Branche: Fertigung
- Mitarbeiter: 500
- Standorte: 3 (DACH-Region)

### Ausgangssituation
- Aktuelles ERP: SAP R/3 (15 Jahre alt)
- Probleme: Performance, keine Cloud-Anbindung
- Budget: 500.000 EUR
- Zeitrahmen: 12 Monate

### Ziele
- Migration auf D365 Finance & SCM
- Integration mit bestehendem CRM (Salesforce)
- Automatisierung der Lagerverwaltung

---

## Fragen

1. @research Was sind die Hauptunterschiede zwischen SAP R/3 und D365 Finance?

2. @research Welche D365-Module sind fÃ¼r ein Fertigungsunternehmen relevant?

3. @architekt Erstelle eine High-Level-Architektur fÃ¼r die D365-Salesforce-Integration

4. @architekt Welche Datenmigrationsstrategie empfiehlst du fÃ¼r die SAP-Migration?

5. @pm Erstelle einen Projektplan mit Meilensteinen fÃ¼r die 12-monatige EinfÃ¼hrung

6. @pm Welche Ressourcen und Rollen werden fÃ¼r das Projekt benÃ¶tigt?

7. @research Welche Risiken gibt es bei einer SAP-zu-D365-Migration?

8. @pm Erstelle eine Risikomatrix basierend auf den identifizierten Risiken
```

**AusfÃ¼hren:**

```bash
# Dry-Run (Vorschau)
python main.py Agents process-file projekt_fragen.md --dry-run -p 99

# TatsÃ¤chlich ausfÃ¼hren
python main.py Agents process-file projekt_fragen.md -p 99

# Mit Debug-Ausgabe
python main.py Agents process-file projekt_fragen.md -p 99 -d
```

---

### Setup verifizieren

PrÃ¼fen Sie, ob alles korrekt konfiguriert ist:

```bash
# 1. Agenten auflisten
python main.py Agents list-agents

# 2. Wissensdatenbank prÃ¼fen
python main.py RAG list-knowledge

# 3. Test-Frage stellen
python main.py Agents ask "@research Was ist D365 Finance?" -p 99

# 4. Chat-Modus testen
python main.py Agents chat -p 99
```

**Erwartete Ausgabe (list-agents):**
```
Available Agents:

research
  Name: Research Agent
  Role: researcher
  LLM: ollama / llama3
  Tools: web_search, query_knowledge_base, list_projects, save_markdown
  Mentions: @research, @res, @r

architekt
  Name: Solution Architekt
  Role: architect
  LLM: openai / gpt-4.1
  ...
```

---

## Markdown-Format

### Grundstruktur

Eine Eingabedatei besteht aus zwei Teilen:

1. **Kontext** - Alles vor der ersten nummerierten Frage
2. **Fragen** - Nummerierte Liste mit optionalen @Agent-Mentions

### Beispiel-Eingabedatei

```markdown
# Projektname: D365 Finance Integration

## Hintergrund
Das Unternehmen mÃ¶chte seine bestehende ERP-LÃ¶sung durch
Microsoft Dynamics 365 Finance ersetzen. Die Integration
mit dem bestehenden CRM-System ist erforderlich.

## Budget
500.000 EUR

## Zeitrahmen
12 Monate

1. @research Was sind die Hauptfunktionen von D365 Finance?

2. @architekt Wie sollte die Integration mit dem CRM aufgebaut werden?

3. @pm Erstelle einen groben Projektplan fÃ¼r die EinfÃ¼hrung

4. Welche Risiken gibt es bei der Migration?
```

### Regeln fÃ¼r das Format

| Element | Regel |
|---------|-------|
| **Kontext** | Beliebiger Text vor der ersten nummerierten Frage |
| **Fragen** | MÃ¼ssen nummeriert sein: `1.`, `2.`, `3.` usw. |
| **@Mention** | Optional, bestimmt den Agenten (Standard: research) |
| **Fragetext** | Beliebiger Text nach der Nummer (und optional @Mention) |

---

## Ausgabeformat

Nach der Verarbeitung werden die Antworten direkt unter den Fragen eingefÃ¼gt.
**Die Fragen werden als Ãœberschriften formatiert und der @agent-Teil wird entfernt:**

### Vorher (Eingabe)

```markdown
# Projekt

Kontext zum Projekt...

1. @research Was ist D365?

2. @pm Erstelle einen Zeitplan
```

### Nachher (Ausgabe)

```markdown
# Projekt

Kontext zum Projekt...

### Was ist D365?

Microsoft Dynamics 365 ist eine Suite von
Enterprise-Anwendungen, die ERP- und CRM-FunktionalitÃ¤ten
kombiniert...

### Erstelle einen Zeitplan

Basierend auf dem Projektkontext empfehle ich
folgenden Zeitplan:
- Phase 1: Analyse (4 Wochen)
- Phase 2: Design (6 Wochen)
...
```

### Inkrementelles Schreiben

Die Ausgabedatei wird **nach jeder beantworteten Frage** geschrieben, nicht erst am Ende. So kÃ¶nnen Sie:
- Den Fortschritt live verfolgen
- Bei Abbruch bereits beantwortete Fragen behalten
- Lange Verarbeitungen jederzeit unterbrechen

### Kontext-Verkettung

Nachfolgende Fragen erhalten automatisch **alle** vorherigen Antworten als Kontext. So kÃ¶nnen Sie sich auf vorherige Antworten beziehen:

```markdown
1. @research Was ist D365 Finance?

2. @research ErklÃ¤re das genauer  # Bezieht sich auf Antwort 1

3. @pm Basierend auf den Informationen, erstelle einen Plan  # Bezieht sich auf Antworten 1+2
```

---

## VerfÃ¼gbare Agenten

Die Agenten kÃ¶nnen Ã¼ber Konfigurationsdateien angepasst werden. Siehe Abschnitt [Agent-Konfiguration](#agent-konfiguration) fÃ¼r Details.

### @research (Standard)

**Aliases:** `@research`, `@res`, `@r`

Der Research-Agent ist spezialisiert auf:
- Faktenrecherche
- Informationssammlung
- Wissensbasis-Abfragen

**LLM:** Ollama (lokal)

**Beispiel:**
```markdown
1. @research Was ist Microsoft Dynamics 365?
1. @res Welche Module gibt es in D365 Finance?
1. @r ErklÃ¤re den Unterschied zwischen D365 Finance und Business Central
```

### @architekt

**Aliases:** `@architekt`, `@architect`, `@arch`, `@sa`

Der Solution Architekt ist spezialisiert auf:
- Technische Architektur
- Integrationsdesign
- Systemlandschaften
- Best Practices

**LLM:** Claude Sonnet

**Beispiel:**
```markdown
2. @architekt Erstelle eine Integrationsarchitektur fÃ¼r D365 und Salesforce
2. @arch Welche API-Strategie empfiehlst du?
2. @sa Wie sollte die Datenmigration strukturiert werden?
```

### @projektleiter

**Aliases:** `@projektleiter`, `@pm`, `@pl`, `@project`

Der Projektleiter ist spezialisiert auf:
- Projektplanung
- Ressourcenmanagement
- Risikobewertung
- Meilensteine

**LLM:** Claude Sonnet

**Beispiel:**
```markdown
3. @pm Erstelle einen Projektplan fÃ¼r die D365-EinfÃ¼hrung
3. @projektleiter Welche Ressourcen werden benÃ¶tigt?
3. @pl Identifiziere die kritischen Meilensteine
```

---

## Wissensdatenbank

Das System verwendet zwei separate Wissensdatenbanken:

### Projekt-Wissensbasis (rag_collection)

Projektspezifische Dokumente mit `project_id`:

```bash
# Dokumente zu Projekt 99 importieren
python main.py RAG addfiles -f ./projekt_docs -p 99

# Projekt-Dokumente anzeigen
python main.py RAG delete --project 99 --dry-run
```

### Globale Wissensdatenbank (knowledge_base)

Allgemeines Wissen (D365 Doku, Best Practices, etc.) **ohne** project_id:

```bash
# Globales Wissen importieren
python main.py RAG add-knowledge -f ./d365_documentation

# Inhalt anzeigen
python main.py RAG list-knowledge

# LÃ¶schen
python main.py RAG delete-knowledge --file "D365_Guide.pdf"
python main.py RAG delete-knowledge --all
```

### Automatische kombinierte Suche

Bei jeder RAG-Abfrage werden **BEIDE** Datenbanken durchsucht:

```
Abfrage: "Was ist D365 Finance?"
    â”‚
    â”œâ”€â”€â–º Suche in rag_collection (Projekt) â†’ 3 Ergebnisse
    â”‚
    â”œâ”€â”€â–º Suche in knowledge_base (Global) â†’ 2 Ergebnisse
    â”‚
    â””â”€â”€â–º Kombinierte Antwort: 5 Ergebnisse
```

**Beispiel-Output:**
```
[1] [Projekt 99] Anforderungen.pdf
Die Anforderungen fÃ¼r das System sind...

---

[2] [Projekt 99] Timeline.xlsx
Der Zeitplan sieht vor...

---

[3] [Wissensdatenbank] D365_Finance_Guide.pdf
D365 Finance ist ein ERP-Modul fÃ¼r...
```

---

## CLI-Befehle

### Markdown-Verarbeitung

```bash
python main.py Agents process-file <DATEI> [OPTIONEN]
```

| Option | Kurz | Beschreibung |
|--------|------|--------------|
| `--project` | `-p` | Filtert RAG-Abfragen auf ein bestimmtes Projekt |
| `--debug` | `-d` | Zeigt Debug-Ausgabe (System Prompt, Messages, Tool Calls) |
| `--dry-run` | `--dry` | Zeigt Antworten an, ohne die Datei zu Ã¤ndern |
| `--output` | `-o` | Schreibt in eine andere Datei statt das Original zu Ã¼berschreiben |

### RAG-Befehle

```bash
# Projekt-Dokumente
python main.py RAG addfiles -f <ORDNER> -p <PROJEKT_ID>
python main.py RAG delete --project <PROJEKT_ID>
python main.py RAG delete --file <DATEINAME>

# Globale Wissensdatenbank
python main.py RAG add-knowledge -f <ORDNER>
python main.py RAG list-knowledge
python main.py RAG delete-knowledge --file <DATEINAME>
python main.py RAG delete-knowledge --all
```

### Agent-Befehle

```bash
# Einzelne Frage stellen
python main.py Agents ask "@research Was ist D365?" -p 99
python main.py Agents ask "@architekt Erstelle eine Architektur" -d

# Agenten auflisten
python main.py Agents list-agents

# Orchestrierung (Supervisor delegiert)
python main.py Agents orchestrate "Analysiere das Projekt"

# Interaktiver Chat-Modus
python main.py Agents chat -p 99
python main.py Agents chat -p 99 -d  # Mit Debug-Ausgabe
```

---

## Interaktiver Chat-Modus

Der Chat-Modus ermÃ¶glicht eine interaktive Unterhaltung mit den Agenten. Der Chat-Verlauf wird automatisch als Kontext an nachfolgende Fragen Ã¼bergeben.

### Starten

```bash
python main.py Agents chat -p 99
```

### Funktionsweise

```
ğŸš€ FSCM Chat Mode
ğŸ“ Projekt: 99
ğŸ’¡ Agenten: @research, @architekt, @pm (Standard: research)
ğŸ’¡ Befehle: exit, clear, help

You: @research Was ist D365 Finance?

ğŸ”§ Research:
Microsoft Dynamics 365 Finance ist ein ERP-Modul fÃ¼r...

You: ErklÃ¤re das genauer

ğŸ”§ Research:
Basierend auf meiner vorherigen Antwort mÃ¶chte ich ergÃ¤nzen...

You: @architekt Wie wÃ¼rdest du das implementieren?

ğŸ”§ Architekt:
Basierend auf den Informationen zu D365 Finance empfehle ich...

You: clear
ğŸ—‘ï¸ Chat-Verlauf gelÃ¶scht.

You: exit
ğŸ‘‹ Chat beendet.
```

### Chat-Befehle

| Befehl | Beschreibung |
|--------|--------------|
| `exit` | Chat beenden |
| `clear` | Chat-Verlauf lÃ¶schen (Kontext wird zurÃ¼ckgesetzt) |
| `help` | Hilfe anzeigen |
| `Ctrl+C` | Chat sofort beenden |

### Kontext-Verkettung

Der Chat-Verlauf wird automatisch als Kontext an jede neue Frage angehÃ¤ngt. So kÃ¶nnen Sie:
- Auf vorherige Antworten Bezug nehmen
- Folgefragen stellen ohne Wiederholung
- Zwischen Agenten wechseln (der Kontext bleibt erhalten)

---

## Rate-Limit-Handling

Das System behandelt API-Rate-Limits (429-Fehler) automatisch:

```
Frage 1 â†’ OK
Frage 2 â†’ OK
...
Frage 26 â†’ 429 Error
         â†’ "â³ Rate limit (429) - warte 60s vor Retry..."
         â†’ [60 Sekunden Pause]
         â†’ Retry â†’ OK
Frage 27 â†’ OK
```

**Konfiguration:**
- Max. 3 Retries
- Exponentielles Backoff: 60s â†’ 120s â†’ 240s (max. 5 min)
- Meldung erscheint auch ohne Debug-Mode

**Kontext-Ãœbergabe:**
- Alle vorherigen Antworten werden als Kontext an nachfolgende Fragen Ã¼bergeben
- Bei sehr vielen Fragen kann dies zu groÃŸen Token-Mengen fÃ¼hren

---

## Projekt-Filter

Mit dem `--project` / `-p` Parameter kÃ¶nnen RAG-Abfragen auf ein bestimmtes Projekt eingeschrÃ¤nkt werden.

### Verwendung

```bash
# Nur Dokumente aus Projekt 99 durchsuchen
python main.py Agents process-file fragen.md -p 99
```

### Funktionsweise

Wenn ein Projekt-Filter aktiv ist:
1. Projekt-Dokumente werden mit dem Filter durchsucht
2. Die **globale Wissensdatenbank wird IMMER zusÃ¤tzlich** durchsucht
3. Beide Ergebnisse werden kombiniert

| Situation | Empfehlung |
|-----------|------------|
| Fragen zu einem bestimmten Projekt | `-p <projekt_id>` verwenden |
| Allgemeine Fragen zu D365 | Keinen Filter verwenden |
| Vergleich zwischen Projekten | Keinen Filter verwenden |

---

## Debug-Modus

Der Debug-Modus zeigt detaillierte Informationen Ã¼ber die Agent-AusfÃ¼hrung an.

### Verwendung

```bash
python main.py Agents process-file fragen.md -d
```

### Ausgabe im Debug-Modus

| Information | Beschreibung |
|-------------|--------------|
| **System Prompt** | Der vollstÃ¤ndige System Prompt des Agents |
| **User Query** | Die an den Agent gesendete Anfrage (Kontext + Frage) |
| **Available Tools** | Liste der verfÃ¼gbaren Tools |
| **Iteration X** | Jeder LLM-Aufruf |
| **LLM Response** | Die Antwort des LLMs |
| **Tool Call** | Welches Tool mit welchen Argumenten aufgerufen wird |
| **Tool Result** | Das Ergebnis des Tool-Aufrufs |
| **Rate Limit** | Informationen zu Rate-Limit-Retries |

---

## Agent-Konfiguration

Die Agenten sind vollstÃ¤ndig konfigurierbar Ã¼ber zwei Arten von Dateien:

### Verzeichnisstruktur

```
FSCMV3/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ agents.yaml         # LLM-Konfiguration (Provider, Model, Tools, Role-File)
â”œâ”€â”€ roles/
â”‚   â”œâ”€â”€ research.md         # System Prompt (ausfÃ¼hrlich)
â”‚   â”œâ”€â”€ projektleiter.md    # System Prompt (ausfÃ¼hrlich)
â”‚   â”œâ”€â”€ architekt.md        # System Prompt (ausfÃ¼hrlich)
â”‚   â”œâ”€â”€ supervisor.md       # System Prompt (ausfÃ¼hrlich)
â”‚   â”œâ”€â”€ de/                 # Minimale deutsche Rollen
â”‚   â”‚   â”œâ”€â”€ research.md
â”‚   â”‚   â”œâ”€â”€ projektleiter.md
â”‚   â”‚   â”œâ”€â”€ architekt.md
â”‚   â”‚   â””â”€â”€ supervisor.md
â”‚   â””â”€â”€ en/                 # Minimale englische Rollen
â”‚       â”œâ”€â”€ research.md
â”‚       â”œâ”€â”€ project_manager.md
â”‚       â”œâ”€â”€ architect.md
â”‚       â””â”€â”€ supervisor.md
```

### LLM-Konfiguration (config/agents.yaml)

```yaml
agents:
  research:
    name: "Research Agent"
    role: "researcher"
    role_file: "de/research.md"      # Pfad relativ zu roles/
    llm_provider: "ollama"           # ollama, claude, openai
    model: "gpt-oss:120b-cloud"
    temperature: 0.3
    tools:
      - "web_search"
      - "query_knowledge_base"
      - "list_projects"
      - "save_markdown"

  projektleiter:
    name: "Projektleiter"
    role: "project_manager"
    role_file: "de/projektleiter.md"
    llm_provider: "openai"
    model: "gpt-4.1"
    temperature: 0.3
    tools:
      - "all"

  architekt:
    name: "Solution Architekt"
    role: "architect"
    role_file: "de/architekt.md"
    llm_provider: "openai"
    model: "gpt-4.1"
    temperature: 0.3
    tools:
      - "query_knowledge_base"
      - "list_projects"
      - "web_search"
      - "save_markdown"
```

### Role-File Konfiguration

Das `role_file` Feld bestimmt, welche Markdown-Datei als System-Prompt verwendet wird:

| Wert | Pfad | Beschreibung |
|------|------|--------------|
| `"research.md"` | `roles/research.md` | AusfÃ¼hrlicher System-Prompt (~1700 Zeilen) |
| `"de/research.md"` | `roles/de/research.md` | Minimaler System-Prompt auf Deutsch (~25 Zeilen) |
| `"en/research.md"` | `roles/en/research.md` | Minimaler System-Prompt auf Englisch (~25 Zeilen) |

**Wenn `role_file` nicht angegeben ist**, wird automatisch `<agent_name>.md` verwendet.

**Beispiel fÃ¼r englische Agenten:**

```yaml
agents:
  research:
    role_file: "en/research.md"    # English minimal role
  architekt:
    role_file: "en/architect.md"   # English minimal role
  projektleiter:
    role_file: "en/project_manager.md"  # English minimal role
```

### VerfÃ¼gbare LLM-Provider

| Provider | Beschreibung | Beispiel-Modelle |
|----------|--------------|------------------|
| `ollama` | Lokale LLMs via Ollama | `llama3`, `mistral`, `gpt-oss:120b-cloud` |
| `claude` | Anthropic Claude API | `claude-sonnet-4-20250514` |
| `openai` | OpenAI API | `gpt-4`, `gpt-4-turbo` |

### VerfÃ¼gbare Tools

| Tool | Beschreibung |
|------|--------------|
| `query_knowledge_base` | Durchsucht Projekt-Wissensbasis + Globale Wissensdatenbank |
| `list_projects` | Listet alle Projekte in der Wissensbasis |
| `web_search` | Web-Suche via Tavily |
| `save_markdown` | Speichert Ergebnisse als Markdown-Datei |
| `all` | Zugriff auf alle verfÃ¼gbaren Tools |

---

## save_markdown Tool

Das `save_markdown` Tool ermÃ¶glicht es Agenten, Ergebnisse als Markdown-Dateien zu speichern.

### Verwendung

Bitten Sie den Agenten, das Ergebnis zu speichern:

```
You: @research Recherchiere D365 Finance Features und speichere das Ergebnis

ğŸ”§ Research:
[Recherchiert und ruft save_markdown Tool auf]
âœ… Saved to /Users/.../outputs/d365_finance_features.md
```

Oder mit explizitem Dateinamen:

```
You: @architekt Erstelle eine Architektur und speichere sie als api_architektur.md
```

### Parameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `filename` | Dateiname (mit oder ohne .md) | - |
| `content` | Der zu speichernde Inhalt | - |
| `folder` | Zielordner | `./outputs` |

### Ausgabe-Format

Die gespeicherten Dateien enthalten einen Timestamp-Header:

```markdown
<!-- Generated: 2025-02-02T14:30:00.000000 -->

# D365 Finance Features

...
```

### Zugewiesen an

- `research` - Recherche-Ergebnisse speichern
- `architekt` - Architektur-Dokumente speichern
- `projektleiter` - Hat `all` Tools (automatisch enthalten)

### System Prompts (roles/*.md)

Jeder Agent hat eine eigene Markdown-Datei fÃ¼r seinen System Prompt:

**Beispiel: roles/research.md**

```markdown
# Research Agent

Du bist ein Research-Spezialist fÃ¼r D365 Finance and Supply Chain Management.

## Hauptaufgaben

- Recherche von Informationen zu D365 FSCM Features
- Durchsuchen der Wissensdatenbank
- Web-Recherche fÃ¼r aktuelle Dokumentation

## Anweisungen

Antworte immer auf Deutsch und strukturiere deine Ergebnisse klar.
```

---

## Tipps & Best Practices

### Kontext optimieren

Je mehr relevanter Kontext, desto bessere Antworten:

```markdown
# Projekt: ERP-Migration

## Unternehmensprofil
- Branche: Fertigung
- Mitarbeiter: 500
- Standorte: 3 (Deutschland, Ã–sterreich, Schweiz)

## Aktuelle Situation
- Legacy ERP: SAP R/3
- Alter: 15 Jahre
- Hauptprobleme: Performance, fehlende Cloud-Anbindung

1. @research Welche D365-Module sind fÃ¼r Fertigungsunternehmen relevant?
```

### Agent-Auswahl

| Fragetyp | Empfohlener Agent |
|----------|-------------------|
| Was ist...? / ErklÃ¤re... | `@research` |
| Wie funktioniert...? | `@research` |
| Erstelle Architektur... | `@architekt` |
| Welche Technologie...? | `@architekt` |
| Erstelle Projektplan... | `@pm` |
| Welche Ressourcen...? | `@pm` |
| Welche Risiken...? | `@pm` |

### Folgefragen stellen

Nutzen Sie die Kontext-Verkettung fÃ¼r Folgefragen:

```markdown
1. @research Was ist D365 Finance?

2. @research Welche Module hat es?

3. @architekt Wie wÃ¼rdest du diese Module integrieren?

4. @pm Erstelle einen Plan basierend auf der Architektur
```

---

## Fehlerbehebung

### "No questions found"

**Problem:** Keine Fragen wurden erkannt.

**LÃ¶sung:** Stellen Sie sicher, dass Fragen nummeriert sind:
```markdown
# Richtig
1. Was ist D365?
2. Wie funktioniert die Integration?

# Falsch
- Was ist D365?
* Wie funktioniert die Integration?
```

### "Unknown agent"

**Problem:** Agent-Mention wurde nicht erkannt.

**LÃ¶sung:** Verwenden Sie einen gÃ¼ltigen Alias:
```
@research, @res, @r
@architekt, @architect, @arch, @sa
@projektleiter, @pm, @pl, @project
```

### Rate Limit Error (429)

**Problem:** API-Rate-Limit Ã¼berschritten.

**LÃ¶sung:** Das System wartet automatisch und wiederholt die Anfrage. Bei hÃ¤ufigen Fehlern:
- Weniger Fragen auf einmal verarbeiten
- LÃ¤ngere Pausen zwischen DurchlÃ¤ufen
- Claude Opus durch Sonnet ersetzen (hÃ¶heres Limit)

### "Knowledge base is empty"

**Problem:** Keine Dokumente in der Wissensdatenbank.

**LÃ¶sung:**
```bash
# Globales Wissen importieren
python main.py RAG add-knowledge -f ./d365_docs

# Projekt-Dokumente importieren
python main.py RAG addfiles -f ./projekt_docs -p 99
```

---

## LLM-Ãœbersicht

### Aktuell konfigurierte Modelle (agents.yaml)

| Agent | Provider | Modell | Kontext |
|-------|----------|--------|---------|
| Research | Ollama | gpt-oss:120b-cloud | 8K |
| Projektleiter | OpenAI | gpt-4.1 | 1M |
| Architekt | OpenAI | gpt-4.1 | 1M |
| Supervisor | OpenAI | gpt-4.1 | 1M |

---

### Anthropic Claude

| Modell | Kontext-Fenster | StÃ¤rken | SchwÃ¤chen |
|--------|-----------------|---------|-----------|
| **Claude Opus 4.5** | 200K | HÃ¶chste Intelligenz, komplexe Aufgaben, tiefes Reasoning | Teuer, niedrigeres Rate-Limit |
| **Claude Sonnet 4.5** | 200K / 1M (Beta) | Beste Balance QualitÃ¤t/Kosten, sehr gut fÃ¼r Coding & Agents | 1M nur in Tier 4 verfÃ¼gbar |
| **Claude Sonnet 4** | 200K / 1M (Beta) | Schnell, kosteneffizient, gute Coding-FÃ¤higkeiten | Weniger kreativ als Opus |
| **Claude Haiku 3.5** | 200K | Sehr schnell, gÃ¼nstig | Weniger komplex |

**Preise (>200K Tokens):** Input $3â†’$6/MTok, Output $15â†’$22.50/MTok

---

### OpenAI GPT

| Modell | Kontext-Fenster | StÃ¤rken | SchwÃ¤chen |
|--------|-----------------|---------|-----------|
| **GPT-4.1** | 1M | Riesiger Kontext, beste Long-Context Performance | Teuer, langsamer |
| **GPT-4.1 mini** | 1M | GroÃŸer Kontext, kostengÃ¼nstiger | Weniger intelligent als 4.1 |
| **GPT-4o** | 128K | Multimodal, schnell, gut fÃ¼r Allzweck | Kontext kleiner als 4.1 |
| **GPT-4 Turbo** | 128K | Solide Performance | Etwas veraltet |
| **GPT-4** | 8K | BewÃ¤hrt, stabil | Kleiner Kontext! |

---

### Ollama (Lokal)

| Modell | Kontext-Fenster | VRAM benÃ¶tigt | StÃ¤rken | SchwÃ¤chen |
|--------|-----------------|---------------|---------|-----------|
| **Llama 3.1 70B** | 128K | ~40GB | Sehr gut fÃ¼r Coding, Open Source | Hoher VRAM-Bedarf |
| **Llama 3.1 8B** | 128K | ~8GB | Schnell, effizient | Weniger intelligent |
| **Llama 3 Gradient** | 1M+ | 64GB+ | Extrem langer Kontext | Sehr hoher VRAM |
| **Mistral Large 3** | 256K | ~80GB | MoE, effizient, langer Kontext | Nur High-End Hardware |
| **Mistral Small 3.1** | 128K | ~16GB | Gute Balance | - |
| **Mistral Small** | 32K | ~12GB | Schnell, kompakt | KÃ¼rzerer Kontext |

**Hinweis:** Ollama-Kontext kann mit `num_ctx` erhÃ¶ht werden, benÃ¶tigt aber mehr VRAM.

---

### Empfehlungen

| Anwendungsfall | Empfohlenes Modell | BegrÃ¼ndung |
|----------------|-------------------|------------|
| Lange Fragenkataloge | Claude Sonnet 4 (1M), GPT-4.1 | GrÃ¶ÃŸter Kontext |
| Komplexe Architektur | Claude Opus 4.5, GPT-4.1 | HÃ¶chste Intelligenz |
| Kosten/Geschwindigkeit | Ollama lokal, Claude Haiku | GÃ¼nstig/kostenlos |
